{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Emotion_Recognition_project (1) .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6AuwV4Xg6RX",
        "colab_type": "text"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psRV9WWE8tht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07f0f6d4-3049-4b13-81bb-c7ac83c689e4"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random #for random distribution of data\n",
        "from shutil import copyfile\n",
        "from os import getcwd  # getcwd returns current working directory\n",
        "import pandas as pd # for data manipulation\n",
        "import numpy as np # for operation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image # for image processing\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "from zipfile import ZipFile\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cLpMj9pI1q4",
        "colab_type": "text"
      },
      "source": [
        "## **Uploding files from local system**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMOlYM4EJEq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'jaffe.zip'\n",
        "\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8RsD9B7Jm_a",
        "colab_type": "text"
      },
      "source": [
        "## Upload files from Google Drive\n",
        "\n",
        "1.   In this you need to save your datasets in your drive .\n",
        "2.   Then mount your drive (if first time you need   authorization code)\n",
        "3.   At last we flush the drive.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nNzmTfbScCc",
        "colab_type": "text"
      },
      "source": [
        "# Specify your dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6If_kr5PCPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_name = 'jaffe'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmEaCRw1Ju72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_files_from_google_drive(dataset_name):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')   # mounting the drive\n",
        "  \n",
        "  file_name1 = '/content/drive/My Drive/{}.zip'.format(dataset_name)\n",
        "\n",
        "  with ZipFile(file_name1,'r') as zip:\n",
        "    zip.extractall(\"/content/\")\n",
        "    print(\"Successfully imported and extracted files from google drive\")\n",
        "  drive.flush_and_unmount()\n",
        "  print('All changes made in this colab session should now be visible in Drive.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96UBY27BpkBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "684247c4-3524-40fb-fbe2-30a5a6958101"
      },
      "source": [
        "import_files_from_google_drive(dataset_name) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Successfully imported and extracted files from google drive\n",
            "All changes made in this colab session should now be visible in Drive.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ZvFCPrhfDt",
        "colab_type": "text"
      },
      "source": [
        "# Accessing the files in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rleXIrvf86VI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f6d88f85-b9f7-47c5-c2b6-0293a8b843f9"
      },
      "source": [
        "path = \"/content/{}/\".format(dataset_name) # access the path\n",
        "total_num_of_samples = 0 \n",
        "num_of_samples = 0\n",
        "num_of_each_samples = [0]\n",
        "data_dir_list=os.listdir(path)\n",
        "shutil.rmtree(\"/content/{}/\".format(dataset_name) +'/tmp', ignore_errors= True)  # remove that directory tree if tmp named directory exists\n",
        "#class_name = ['anger', 'contempt','disgust','fear','happy','sadness','surprise']\n",
        "if dataset_name == 'jaffe':\n",
        "  class_name = ['0', '1','2','3','4','5','6']\n",
        "else:\n",
        "  class_name = ['anger', 'contempt','disgust','fear','happy','sadness','surprise']\n",
        "for name in class_name:\n",
        "    num_samples = len(os.listdir(path + name))\n",
        "    print(name +': ', num_samples )\n",
        "    num_of_each_samples.append(num_samples)\n",
        "    num_of_samples = num_of_samples + len(os.listdir(path + name))\n",
        "print(num_of_samples)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:  30\n",
            "1:  30\n",
            "2:  29\n",
            "3:  32\n",
            "4:  31\n",
            "5:  31\n",
            "6:  30\n",
            "213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvnFnBMCgJVI",
        "colab_type": "text"
      },
      "source": [
        "# Pre-Processing Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7voYSO8gUh_",
        "colab_type": "text"
      },
      "source": [
        "This section includes pre-processing of images of datasets which are face alignment , cropping , histogram equalization , normalization using z-score normalization . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7k9f7HEy6sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "def HistEqualization(image, number_bins = 256):\n",
        "  # get the image histogram\n",
        "  image_Hist, bins = np.histogram(image.flatten(), number_bins, [0, 256])\n",
        "  cdf = image_Hist.cumsum() # cumulative distribution function\n",
        "  cdf = image_Hist.max()*cdf/cdf.max()  #normalize\n",
        "  cdf_mask = np.ma.masked_equal(cdf, 0)\n",
        "  cdf_mask = (cdf_mask - cdf_mask.min())*255/(cdf_mask.max()-cdf_mask.min())\n",
        "  cdf = np.ma.filled(cdf_mask,0).astype('uint8')\n",
        "  return cdf[image.astype('uint8')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdZdL_qENG4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import math\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import dlib\n",
        "import cv2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDrHKJ2I5Voo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bf04688e-670f-4709-cfff-f68c8865a475"
      },
      "source": [
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bunzip2 \"shape_predictor_68_face_landmarks.dat.bz2\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-20 11:27:58--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  17.2MB/s    in 3.6s    \n",
            "\n",
            "2020-06-20 11:28:02 (17.2 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya-mwC1QISA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor_path = 'shape_predictor_68_face_landmarks.dat'  # path of data\n",
        "\n",
        "#initializes dlib’s pre-trained face detector based on a modification to the standard Histogram of Oriented Gradients + Linear SVM method for object detection.\n",
        "detector = dlib.get_frontal_face_detector() \n",
        "#loads the facial landmark predictor using the path\n",
        "predictor = dlib.shape_predictor(predictor_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3ufXNVAIYC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take a bounding predicted by dlib and convert it\n",
        "def rect_to_bb(rect):\n",
        "\t\n",
        "\t# to the format (x, y, w, h) as we would normally do\n",
        "\t# with OpenCV\n",
        "\tx1 = rect.left()\n",
        "\ty1 = rect.top()\n",
        "\tw1 = rect.right() - x1\n",
        "\th1 = rect.bottom() - y1\n",
        "\n",
        "\t# return a tuple of (x, y, w, h)\n",
        "\treturn (x1, y1, w1, h1)\n",
        " \n",
        "# extract 68 coordinate from shape object \n",
        "def shape_to_np(shape, dtype = int):\n",
        "  \n",
        "  coords = np.zeros((68, 2), dtype=dtype)\n",
        "  for i in range(0,68):\n",
        "    coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "  return coords # loop over the 68 facial landmarks and convert them\n",
        "\n",
        "# calculate forehead distance to use in cropping image\n",
        "def forehead_dist(coords):\n",
        "\n",
        "  d = (np.sum(coords[42:47,1]) - np.sum(coords[36:41,1]))/ 6\n",
        "  return d\n",
        "\n",
        "# calculate angle using eye landmark points i.e 42 to 47 is right eye and 36 to 41 is left eye \n",
        "def required_angle(shape):\n",
        "\t\n",
        "  val = (np.sum(shape[42:47,1]) - np.sum(shape[36:41,1]))/(np.sum(shape[42:47,0]) - np.sum(shape[36:41,0])) \n",
        "  angle = math.degrees(math.atan(val))\n",
        "  return angle\n",
        "\n",
        "#finally rotate image obtained by required_angle function\n",
        "def rotate_image(image, shape):\n",
        "  \n",
        "  angle = required_angle(shape)\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  rotated_image = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return rotated_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAXnJ-k4IjA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_alignment(image):\n",
        "\n",
        "  gray_image = cv2.cvtColor(image ,cv2.COLOR_BGR2GRAY)  # convert color image to grayscale image\n",
        "  rects = detector(gray_image ,1)             # detect faces in the grayscale image\n",
        "  if len(rects) > 0:\n",
        "\n",
        "    images = []\n",
        "    for (i, rect) in enumerate(rects):\n",
        "      shape = predictor(image, rect)\n",
        "      shape = shape_to_np(shape)\n",
        "\n",
        "      rotated_image = rotate_image(image , shape)\n",
        "      images.append(rotated_image)\n",
        "    if len(rects) == 1 :\n",
        "      return rotated_image\n",
        "    else:\n",
        "      return images\n",
        "  else:\n",
        "    print(\"Error : number of detected face is zero, so we just return original image\")\n",
        "    return image\n",
        "  \n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM3TU7sNd9Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_cropping_without_forehead(image):\n",
        "\n",
        "  gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  # convert color image to grayscale image\n",
        "  rects = detector(gray_image ,1)             # detect faces in the grayscale image\n",
        "  if len(rects) > 0:\n",
        "    images = []\n",
        "    for (i, rect) in enumerate(rects):\n",
        "\t\n",
        "      shape = predictor(image, rect)\n",
        "      shape = shape_to_np(shape)\n",
        "    \n",
        "      # convert dlib's rectangle to a OpenCV-style bounding box\n",
        "      # [i.e., (x, y, w, h)], then draw the face bounding box\n",
        "      (x1, y1, w1, h1) = rect_to_bb(rect)\n",
        "\n",
        "      d = forehead_dist(shape)\n",
        "      top_y = int(np.sum(shape[42 : 47, 1]) / 6 - 0.6 * d)\n",
        "      left_x, left_y = shape[0]\n",
        "      bottom_x, bottom_y = shape[8]\n",
        "      right_x, right_y = shape[16]\n",
        "      cropped_image = image[top_y : bottom_y, left_x : right_x]\n",
        "      if cropped_image.shape[0] == 0: \n",
        "        cropped_image = image[0:-1,left_x : right_x] \n",
        "      if cropped_image.shape[1] == 0:\n",
        "        cropped_image = image[top_y : bottom_y,  0:-1]\n",
        "      images.append(cropped_image)\n",
        "    if len(rects) == 1 :\n",
        "      return cropped_image\n",
        "    else:\n",
        "      return images\n",
        "\n",
        "  \n",
        "  else:\n",
        "    print(\"Error : number of detected face is zero, so we just return original image\")\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE-_kE0KCPeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def face_cropping_without_background(image):\n",
        "\n",
        "  gray_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  # convert color image to grayscale image\n",
        "  rects = detector(gray_image ,1)             # detect faces in the grayscale image\n",
        "  if len(rects) > 0:\n",
        "    images = []\n",
        "    for (i, rect) in enumerate(rects):\n",
        "\t\n",
        "      shape = predictor(image, rect)\n",
        "      shape = shape_to_np(shape)\n",
        "    \n",
        "      # convert dlib's rectangle to a OpenCV-style bounding box\n",
        "      # [i.e., (x, y, w, h)], then draw the face bounding box\n",
        "      (x1, y1, w1, h1) = rect_to_bb(rect)\n",
        "\n",
        "      top_x, top_y = shape[19]\n",
        "      left_x, left_y = shape[0]\n",
        "      bottom_x, bottom_y = shape[8]\n",
        "      right_x, right_y = shape[16]\n",
        "      cropped_image = image[ min(top_y, abs(y1)) : max(bottom_y, abs(y1) + w1), min(left_x, abs(x1)) : max(right_x, abs(x1) + w1)]\n",
        "      if cropped_image.shape[0] == 0: \n",
        "        cropped_image = image[:,min(left_x, abs(x1)) : max(right_x, abs(x1) + w1)] \n",
        "      if cropped_image.shape[1] == 0:\n",
        "        cropped_image = image[min(top_y, abs(y1)) : max(bottom_y, abs(y1) + w1), :]\n",
        "      images.append(cropped_image)\n",
        "    if len(rects) == 1 :\n",
        "      return cropped_image\n",
        "    else:\n",
        "      return images\n",
        "  else:\n",
        "    print(\"Error : number of detected face is zero, so we just return original image\")\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEdQ-kyllnDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "data_dir_list = os.listdir(path)\n",
        "image_data = []\n",
        "\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(path+'/'+ dataset)\n",
        "    \n",
        "    for img in img_list:\n",
        "      input_img=cv2.imread(path + '/'+ dataset + '/'+ img  )\n",
        "      #cv2_imshow(input_img)\n",
        "      img1 = face_alignment(input_img)\n",
        "      img2 = face_cropping_without_forehead(img1)\n",
        "      img2 = cv2.resize(img2,(32,32))\n",
        "      HEG_image = HistEqualization(img2)\n",
        "      normalized_img = stats.zscore(HEG_image)\n",
        "      normalized_img = normalized_img*255\n",
        "      img = normalized_img\n",
        "      #cv2_imshow(img)\n",
        "      image_data.append(img)\n",
        "      \n",
        "image_data = np.array(image_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVWTFmcMN-sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48c44891-5017-47cd-ce3c-3d781a4b47a7"
      },
      "source": [
        "print(image_data.shape)\n",
        "print(image_data[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(213, 32, 32, 3)\n",
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNXneXbwhEbB",
        "colab_type": "text"
      },
      "source": [
        "# Splitting the data into training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4RXHRO8JTHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5cdc3dd2-2ec6-4119-f6b9-b9654f32f753"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "num_of_classes = len(class_name)\n",
        "num_of_samples = image_data.shape[0]\n",
        "labels = np.ones((num_of_samples,) , dtype='int64')\n",
        "print(num_of_classes,num_of_samples)\n",
        "print(num_of_each_samples)\n",
        "for i in range( num_of_classes ) :\n",
        "  labels[np.sum(num_of_each_samples[0 : np.max(i + 1, 0) ]) : np.sum(num_of_each_samples[0 : (i + 2)])] = i\n",
        "\n",
        "\n",
        "print(len(labels))\n",
        "\n",
        "def getLabel(id):\n",
        "    #return ['anger','contempt','disgust','fear','happy','sadness','surprise'][id]\n",
        "    return ['0','1','2','3','4','5','6'][id]\n",
        "\n",
        "Y = np_utils.to_categorical(labels, num_of_classes)\n",
        " \n",
        "x,y = image_data,Y\n",
        "\n",
        "#print(len(x),len(y))\n",
        "#X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "test_size = 0.2\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "\n",
        "for i in range(num_of_classes):\n",
        "  X_train_t , X_test_t, y_train_t, y_test_t = train_test_split( x[np.sum(num_of_each_samples[0 : np.max(i + 1, 0) ]) : np.sum(num_of_each_samples[0 : (i + 2)])],\n",
        "                                                               y[np.sum(num_of_each_samples[0 : np.max(i + 1, 0) ]) : np.sum(num_of_each_samples[0 : (i + 2)])],\n",
        "                                                               test_size = test_size\n",
        "                                                               )\n",
        "  #print(y_test_t.shape, y_train_t.shape)\n",
        "  X_train += list(X_train_t)\n",
        "  X_test += list(X_test_t)\n",
        "  y_train += list(y_train_t)\n",
        "  y_test += list(y_test_t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 213\n",
            "[0, 30, 30, 29, 32, 31, 31, 30]\n",
            "213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrBBbsU4IzT0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ffbb2499-9906-41d2-c01b-ee1c0c6e316a"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))\n",
        "print(len(X_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "168\n",
            "168\n",
            "45\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4jVvA08hsfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqf1OkW38I6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "779708f6-f91d-4c91-ce5a-132a6ced466d"
      },
      "source": [
        "print(X_train.shape)\n",
        "#print(Y_test[1:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(168, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhttO8HxhRYF",
        "colab_type": "text"
      },
      "source": [
        "# Making of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB3Vp4MawJBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_model_with_0_neurons(num_of_classes):\n",
        "  model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (5,5), activation = 'relu', name = 'conv2d_1',),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_1'),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(64,(5,5), activation = 'relu', name = 'conv2d_2'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_2'),\n",
        "        \n",
        "        tf.keras.layers.Flatten(name = 'flatten_1'),\n",
        " \n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_of_classes,activation = 'softmax')\n",
        "    ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtBciV2KtqBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def CNN_model_with_256_neurons(num_of_classes):\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (5,5), activation = 'relu', name = 'conv2d_1',),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_1'),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(64,(5,5), activation = 'relu', name = 'conv2d_2'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_2'),\n",
        "        \n",
        "        tf.keras.layers.Flatten(name = 'flatten_1'),\n",
        "\n",
        "        tf.keras.layers.Dense(256, activation = 'relu', name = \"full_connected_1\"),\n",
        "\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_of_classes,activation = 'softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf1NdonAvtrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_model_with_512_neurons(num_of_classes):\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (5,5), activation = 'relu', name = 'conv2d_1',),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_1'),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(64,(5,5), activation = 'relu', name = 'conv2d_2'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_2'),\n",
        "        \n",
        "        tf.keras.layers.Flatten(name = 'flatten_1'),\n",
        "\n",
        "        tf.keras.layers.Dense(512, activation = 'relu', name = \"full_connected_1\"),\n",
        "\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_of_classes,activation = 'softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqdBOTWCv5Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_model_with_1024_neurons(num_of_classes):\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (5,5), activation = 'relu', name = 'conv2d_1',),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_1'),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(64,(5,5), activation = 'relu', name = 'conv2d_2'),\n",
        "        tf.keras.layers.MaxPooling2D((2,2), name = 'max_pool_2'),\n",
        "        \n",
        "        tf.keras.layers.Flatten(name = 'flatten_1'),\n",
        "\n",
        "        tf.keras.layers.Dense(1024, activation = 'relu', name = \"full_connected_1\"),\n",
        "\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_of_classes,activation = 'softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTFjyGUJhXYn",
        "colab_type": "text"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSudUPJW0VAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac2e864-c5eb-4469-e221-3e28419d4418"
      },
      "source": [
        "train_datagen = image.ImageDataGenerator(\n",
        "    rescale= 1./255,\n",
        "    rotation_range = 2 ,\n",
        "    horizontal_flip =True,\n",
        ")\n",
        "train_datagen.fit(X_train)\n",
        "\n",
        "validation_datagen = image.ImageDataGenerator(rescale = 1./255,\n",
        "                                             rotation_range=2,\n",
        "                                             horizontal_flip = True)\n",
        "validation_datagen.fit(X_test)\n",
        "print(len(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTLPLQXMBVaq",
        "colab_type": "text"
      },
      "source": [
        "Confusion Matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3DQqPooBZMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "#print((X_test))\n",
        "def build_matrix(model, X_test, y_test):\n",
        "  X_test = X_test.astype(dtype = float)\n",
        "  predictions = model.predict(X_test)\n",
        "  y_pred = predictions \n",
        "  matrix = metrics.confusion_matrix(y_test.argmax(axis = 1), y_pred.argmax(axis = 1))\n",
        "  return matrix\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv54HEIm1Kru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (32,32,3)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model = CNN_model_with_512_neurons(num_of_classes)\n",
        "model.compile(optimizer = opt, loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "class myCallback (tf.keras.callbacks.Callback):\n",
        "    def steps_per_epoch(self, epoch, logs = {}):\n",
        "        if logs['accuracy'] > 0.85 :\n",
        "            print('\\nAccuracy reached 85%')\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFqBOxCD1kfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0ad4453-2a41-4bce-dc77-3309c1943dfd"
      },
      "source": [
        "mycallback = myCallback()\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "history = model.fit(train_datagen.flow(X_train, y_train, batch_size=16), \n",
        "                              epochs = 100,\n",
        "                              validation_data=validation_datagen.flow(X_test, y_test, batch_size = 16), \n",
        "                              callbacks = [mycallback] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 2.0232 - accuracy: 0.1488 - val_loss: 1.9152 - val_accuracy: 0.2222\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.9201 - accuracy: 0.1964 - val_loss: 1.8609 - val_accuracy: 0.2889\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.8828 - accuracy: 0.1845 - val_loss: 1.8097 - val_accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.7686 - accuracy: 0.3036 - val_loss: 1.7838 - val_accuracy: 0.3111\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.7359 - accuracy: 0.3512 - val_loss: 1.7359 - val_accuracy: 0.4222\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.7020 - accuracy: 0.3750 - val_loss: 1.6973 - val_accuracy: 0.3556\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.6918 - accuracy: 0.3393 - val_loss: 1.6621 - val_accuracy: 0.5111\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.5846 - accuracy: 0.4464 - val_loss: 1.6336 - val_accuracy: 0.5111\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.5814 - accuracy: 0.3988 - val_loss: 1.6249 - val_accuracy: 0.4222\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.5343 - accuracy: 0.4940 - val_loss: 1.6066 - val_accuracy: 0.4444\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.4697 - accuracy: 0.5119 - val_loss: 1.5852 - val_accuracy: 0.3778\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.4394 - accuracy: 0.4524 - val_loss: 1.5033 - val_accuracy: 0.4889\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 1.4161 - accuracy: 0.5119 - val_loss: 1.5035 - val_accuracy: 0.4889\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.3669 - accuracy: 0.5238 - val_loss: 1.4603 - val_accuracy: 0.5111\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 1.3175 - accuracy: 0.5476 - val_loss: 1.4476 - val_accuracy: 0.5111\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.3732 - accuracy: 0.5595 - val_loss: 1.4163 - val_accuracy: 0.5333\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.2628 - accuracy: 0.5476 - val_loss: 1.3669 - val_accuracy: 0.5556\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.2323 - accuracy: 0.5536 - val_loss: 1.3518 - val_accuracy: 0.4444\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.2264 - accuracy: 0.5536 - val_loss: 1.3744 - val_accuracy: 0.4444\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.2353 - accuracy: 0.5476 - val_loss: 1.3305 - val_accuracy: 0.6222\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 1.1266 - accuracy: 0.6131 - val_loss: 1.2864 - val_accuracy: 0.5778\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 1.0825 - accuracy: 0.6369 - val_loss: 1.2607 - val_accuracy: 0.5778\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 1s 45ms/step - loss: 1.0505 - accuracy: 0.6726 - val_loss: 1.2691 - val_accuracy: 0.5778\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 1.0433 - accuracy: 0.6488 - val_loss: 1.2327 - val_accuracy: 0.6222\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.0370 - accuracy: 0.6548 - val_loss: 1.1925 - val_accuracy: 0.6222\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.9641 - accuracy: 0.6845 - val_loss: 1.1906 - val_accuracy: 0.6000\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 1.0410 - accuracy: 0.6190 - val_loss: 1.1199 - val_accuracy: 0.6000\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.8978 - accuracy: 0.7381 - val_loss: 1.1407 - val_accuracy: 0.6222\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.9330 - accuracy: 0.6964 - val_loss: 1.1068 - val_accuracy: 0.6222\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.9396 - accuracy: 0.6845 - val_loss: 1.0957 - val_accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.8687 - accuracy: 0.7083 - val_loss: 1.0967 - val_accuracy: 0.6444\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.8350 - accuracy: 0.7798 - val_loss: 1.0500 - val_accuracy: 0.6444\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.8959 - accuracy: 0.6845 - val_loss: 1.0523 - val_accuracy: 0.6222\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.7829 - accuracy: 0.7857 - val_loss: 1.0491 - val_accuracy: 0.7111\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.8202 - accuracy: 0.7262 - val_loss: 1.0325 - val_accuracy: 0.6000\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.7697 - accuracy: 0.7321 - val_loss: 1.0372 - val_accuracy: 0.5778\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.7867 - accuracy: 0.7440 - val_loss: 0.9811 - val_accuracy: 0.7556\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.6885 - accuracy: 0.7857 - val_loss: 1.0118 - val_accuracy: 0.6222\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.6716 - accuracy: 0.8393 - val_loss: 0.9803 - val_accuracy: 0.7333\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.6966 - accuracy: 0.7976 - val_loss: 0.9565 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.6463 - accuracy: 0.8036 - val_loss: 0.9779 - val_accuracy: 0.6667\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.6087 - accuracy: 0.8214 - val_loss: 0.9487 - val_accuracy: 0.6667\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.6437 - accuracy: 0.7917 - val_loss: 0.9128 - val_accuracy: 0.7111\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.6158 - accuracy: 0.8393 - val_loss: 0.8821 - val_accuracy: 0.6667\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.6094 - accuracy: 0.7857 - val_loss: 0.9401 - val_accuracy: 0.6889\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.5599 - accuracy: 0.8333 - val_loss: 0.9008 - val_accuracy: 0.7333\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.5913 - accuracy: 0.8214 - val_loss: 0.8947 - val_accuracy: 0.7333\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.5462 - accuracy: 0.8333 - val_loss: 0.9595 - val_accuracy: 0.6444\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.5819 - accuracy: 0.8274 - val_loss: 0.9021 - val_accuracy: 0.6667\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.5634 - accuracy: 0.7976 - val_loss: 0.8921 - val_accuracy: 0.6667\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.5442 - accuracy: 0.8155 - val_loss: 0.9611 - val_accuracy: 0.6000\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.5507 - accuracy: 0.8393 - val_loss: 0.9554 - val_accuracy: 0.6889\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.4915 - accuracy: 0.8393 - val_loss: 0.9760 - val_accuracy: 0.5778\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.4818 - accuracy: 0.8690 - val_loss: 0.8869 - val_accuracy: 0.7333\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.4857 - accuracy: 0.8512 - val_loss: 0.8123 - val_accuracy: 0.6444\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.4687 - accuracy: 0.8869 - val_loss: 0.8471 - val_accuracy: 0.7111\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.4690 - accuracy: 0.8929 - val_loss: 0.8333 - val_accuracy: 0.7333\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.4206 - accuracy: 0.8988 - val_loss: 0.9219 - val_accuracy: 0.6222\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.4044 - accuracy: 0.8631 - val_loss: 0.8162 - val_accuracy: 0.6667\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3974 - accuracy: 0.8869 - val_loss: 0.8307 - val_accuracy: 0.7333\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.4007 - accuracy: 0.8869 - val_loss: 0.7900 - val_accuracy: 0.7333\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3980 - accuracy: 0.8810 - val_loss: 0.8274 - val_accuracy: 0.7111\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3685 - accuracy: 0.9226 - val_loss: 0.8470 - val_accuracy: 0.6889\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.3719 - accuracy: 0.9107 - val_loss: 0.7412 - val_accuracy: 0.7333\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.3941 - accuracy: 0.9226 - val_loss: 0.8317 - val_accuracy: 0.7111\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3631 - accuracy: 0.8929 - val_loss: 0.7607 - val_accuracy: 0.7556\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3702 - accuracy: 0.8929 - val_loss: 0.8120 - val_accuracy: 0.6889\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3354 - accuracy: 0.9167 - val_loss: 0.7576 - val_accuracy: 0.7556\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 43ms/step - loss: 0.3813 - accuracy: 0.8869 - val_loss: 0.8255 - val_accuracy: 0.6889\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3063 - accuracy: 0.9286 - val_loss: 0.7369 - val_accuracy: 0.7333\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.3825 - accuracy: 0.8690 - val_loss: 0.7051 - val_accuracy: 0.7778\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.3577 - accuracy: 0.9226 - val_loss: 0.8165 - val_accuracy: 0.7111\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.3453 - accuracy: 0.9167 - val_loss: 0.7122 - val_accuracy: 0.8000\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2980 - accuracy: 0.9345 - val_loss: 0.8147 - val_accuracy: 0.7111\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.3250 - accuracy: 0.9107 - val_loss: 0.7026 - val_accuracy: 0.8000\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.3078 - accuracy: 0.9226 - val_loss: 0.8000 - val_accuracy: 0.7556\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.3077 - accuracy: 0.9167 - val_loss: 0.7392 - val_accuracy: 0.8000\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2652 - accuracy: 0.9464 - val_loss: 0.8229 - val_accuracy: 0.7111\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.3120 - accuracy: 0.9167 - val_loss: 0.7144 - val_accuracy: 0.8000\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2295 - accuracy: 0.9643 - val_loss: 0.7729 - val_accuracy: 0.7111\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2916 - accuracy: 0.9226 - val_loss: 0.7484 - val_accuracy: 0.7556\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2932 - accuracy: 0.9405 - val_loss: 0.7995 - val_accuracy: 0.7111\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2968 - accuracy: 0.9345 - val_loss: 0.7581 - val_accuracy: 0.7333\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2990 - accuracy: 0.9226 - val_loss: 0.7369 - val_accuracy: 0.7556\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 44ms/step - loss: 0.2350 - accuracy: 0.9286 - val_loss: 0.7035 - val_accuracy: 0.8000\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2702 - accuracy: 0.9464 - val_loss: 0.7347 - val_accuracy: 0.7556\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2424 - accuracy: 0.9464 - val_loss: 0.6911 - val_accuracy: 0.7778\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2356 - accuracy: 0.9464 - val_loss: 0.6898 - val_accuracy: 0.7333\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2536 - accuracy: 0.9286 - val_loss: 0.7346 - val_accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.2481 - accuracy: 0.9226 - val_loss: 0.7369 - val_accuracy: 0.7556\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 45ms/step - loss: 0.2544 - accuracy: 0.9345 - val_loss: 0.7492 - val_accuracy: 0.7778\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2323 - accuracy: 0.9345 - val_loss: 0.7284 - val_accuracy: 0.7556\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2279 - accuracy: 0.9464 - val_loss: 0.7240 - val_accuracy: 0.8000\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2164 - accuracy: 0.9464 - val_loss: 0.6848 - val_accuracy: 0.7556\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 1s 47ms/step - loss: 0.1972 - accuracy: 0.9524 - val_loss: 0.7904 - val_accuracy: 0.7556\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2757 - accuracy: 0.8988 - val_loss: 0.7020 - val_accuracy: 0.7778\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2144 - accuracy: 0.9524 - val_loss: 0.6796 - val_accuracy: 0.8000\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.2091 - accuracy: 0.9464 - val_loss: 0.7279 - val_accuracy: 0.7333\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.1988 - accuracy: 0.9405 - val_loss: 0.7230 - val_accuracy: 0.7778\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 1s 46ms/step - loss: 0.1768 - accuracy: 0.9583 - val_loss: 0.7344 - val_accuracy: 0.7778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDLuaxCJ63G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "historys = []\n",
        "historys.append(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8nIyOynMDiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "89a3976c-a26c-400b-d39e-1e5b1a658eab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i,history in enumerate(historys):\n",
        "  acc=history.history['accuracy']\n",
        "  val_acc=history.history['val_accuracy']\n",
        "  loss=history.history['loss']\n",
        "  val_loss=history.history['val_loss']\n",
        "  epochs=range(len(acc)) # Get number of epochs\n",
        "  fig = plt.figure(figsize= (12,8))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, acc, 'r',label =  \"Training Accuracy\")\n",
        "  plt.plot(epochs, val_acc, 'b',label = \"Validation Accuracy\")\n",
        "  plt.title('Training and validation accuracy({} neurons)'.format(i *256))\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "  plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "  plt.legend()\n",
        "  plt.title('Training and validation loss({} neurons)'.format(256))\n",
        "\n",
        "  fig.savefig('history_{}neurons.jpg'.format(i *256),bbox_inches='tight', dpi=150)\n",
        "\n",
        "  plt.show()\n",
        "  from google.colab import files\n",
        "  files.download('history_{}neurons.jpg'.format(i *256))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSi8NDY69-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ce9973ba-9903-4faf-d7a3-3afa763be405"
      },
      "source": [
        "matrix = build_matrix(model, X_test , y_test)\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5 0 0 0 0 1 0]\n",
            " [0 6 0 0 0 0 0]\n",
            " [0 0 6 0 0 0 0]\n",
            " [0 0 1 4 1 1 0]\n",
            " [0 1 0 0 6 0 0]\n",
            " [0 0 0 0 2 5 0]\n",
            " [1 1 0 0 0 2 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW4iD3vaw5dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Just a try to check the use of kfold\n",
        "for train_ind, test_ind in kf.split(list(range(num_of_samples))):\n",
        "  print(train_ind,test_ind)\n",
        "  print(train_ind[1])\n",
        "  cv2_imshow(image_data[train_ind[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkiQ7PjLMhdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2adb441-6917-4794-abd9-e8904494a105"
      },
      "source": [
        "# ten fold cross validation on the whole dataset \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "acc = 0\n",
        "\n",
        "kf = KFold(n_splits = 10, random_state = 10, shuffle = True)\n",
        "\n",
        "kf.get_n_splits(image_data)\n",
        "\n",
        "\n",
        "for train_index,test_index in kf.split(image_data):\n",
        "\n",
        "  #print(train_index,test_index)\n",
        "  x_val_train,x_val_test = image_data[train_index],image_data[test_index]\n",
        "  y_val_train,y_val_test = Y[train_index], Y[test_index]\n",
        "  #print( y_val_train,y_val_test)\n",
        "\n",
        "\n",
        "  \n",
        "  model = CNN_model_with_0_neurons(num_of_classes)\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "  \n",
        "  model.fit(x_val_train,y_val_train,epochs=100)\n",
        "  test_loss,test_acc=model.evaluate(x_val_test,y_val_test)\n",
        "  print(test_acc)\n",
        "  acc += test_acc\n",
        "  #print(test_loss,test_acc )\n",
        "  #model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  #optimizer='adam',\n",
        "                  #metrics=['accuracy'])\n",
        "  #model.fit(x_val_train,y_val_train,epochs=80)\n",
        "  #test_loss,test_acc=model.evaluate(x_val_test,y_val_test)\n",
        "#cross_val_score(model,x_val_test,y_val_tes,cv=10)  \n",
        "print(acc/10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 215.5109 - accuracy: 0.1466\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 31.7005 - accuracy: 0.1623\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 7.2675 - accuracy: 0.2461\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 2.0597 - accuracy: 0.2513\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.8924 - accuracy: 0.1885\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8874 - accuracy: 0.1623\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8629 - accuracy: 0.2408\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8014 - accuracy: 0.2461\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8128 - accuracy: 0.2513\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7906 - accuracy: 0.2723\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.7077 - accuracy: 0.3508\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.6657 - accuracy: 0.3351\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6611 - accuracy: 0.3403\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5437 - accuracy: 0.3560\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4773 - accuracy: 0.3874\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4811 - accuracy: 0.4084\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5079 - accuracy: 0.3822\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4136 - accuracy: 0.4712\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3453 - accuracy: 0.4764\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3338 - accuracy: 0.5079\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2039 - accuracy: 0.5759\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2220 - accuracy: 0.5445\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3168 - accuracy: 0.4817\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1123 - accuracy: 0.5812\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9539 - accuracy: 0.6283\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1397 - accuracy: 0.6073\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0190 - accuracy: 0.6178\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8832 - accuracy: 0.6702\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7463 - accuracy: 0.7435\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6817 - accuracy: 0.7958\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.5964 - accuracy: 0.8063\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.5203 - accuracy: 0.7853\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5499 - accuracy: 0.7853\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6815 - accuracy: 0.7487\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5475 - accuracy: 0.8220\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5437 - accuracy: 0.8272\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5822 - accuracy: 0.8115\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.4643 - accuracy: 0.8534\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3962 - accuracy: 0.8691\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5399 - accuracy: 0.8010\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4717 - accuracy: 0.8534\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3558 - accuracy: 0.8482\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3941 - accuracy: 0.8691\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2850 - accuracy: 0.9005\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2540 - accuracy: 0.9110\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1612 - accuracy: 0.9424\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2529 - accuracy: 0.9215\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1816 - accuracy: 0.9529\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.1568 - accuracy: 0.9319\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1498 - accuracy: 0.9529\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1274 - accuracy: 0.9581\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0839 - accuracy: 0.9738\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0988 - accuracy: 0.9581\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0890 - accuracy: 0.9686\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.1105 - accuracy: 0.9581\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0948 - accuracy: 0.9686\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0982 - accuracy: 0.9686\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0525 - accuracy: 0.9843\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0419 - accuracy: 0.9948\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0442 - accuracy: 0.9738\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0737 - accuracy: 0.9791\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0654 - accuracy: 0.9738\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0699 - accuracy: 0.9686\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0914 - accuracy: 0.9634\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0356 - accuracy: 0.9843\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0648 - accuracy: 0.9843\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.1050 - accuracy: 0.9529\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1297 - accuracy: 0.9424\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.1999 - accuracy: 0.9424\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0986 - accuracy: 0.9529\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0705 - accuracy: 0.9843\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1082 - accuracy: 0.9738\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0423 - accuracy: 0.9843\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0257 - accuracy: 0.9948\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0368 - accuracy: 0.9895\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0317 - accuracy: 0.9895\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0227 - accuracy: 0.9895\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0317 - accuracy: 0.9948\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0241 - accuracy: 0.9895\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0578 - accuracy: 0.9948\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0692 - accuracy: 0.9686\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0620 - accuracy: 0.9738\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0460 - accuracy: 0.9843\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0677 - accuracy: 0.9791\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1491 - accuracy: 0.9791\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0707 - accuracy: 0.9791\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0620 - accuracy: 0.9843\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0267 - accuracy: 0.9895\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0568 - accuracy: 0.9791\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0389 - accuracy: 0.9895\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0297 - accuracy: 0.9843\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0501 - accuracy: 0.9843\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0237 - accuracy: 0.9948\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0266 - accuracy: 0.9895\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0498 - accuracy: 0.9843\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0173 - accuracy: 0.9948\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0184 - accuracy: 0.9948\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0272 - accuracy: 0.9895\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0559 - accuracy: 0.9843\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8757 - accuracy: 0.5909\n",
            "0.5909090638160706\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 184.3773 - accuracy: 0.1361\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 15.4576 - accuracy: 0.2356\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 4.5047 - accuracy: 0.1937\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 2.0286 - accuracy: 0.2147\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9523 - accuracy: 0.1832\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.9065 - accuracy: 0.1832\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8901 - accuracy: 0.1885\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.8837 - accuracy: 0.2618\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7892 - accuracy: 0.2827\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8142 - accuracy: 0.2356\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7735 - accuracy: 0.2880\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.7249 - accuracy: 0.2723\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7104 - accuracy: 0.2670\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6916 - accuracy: 0.2932\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.6600 - accuracy: 0.2827\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6711 - accuracy: 0.3298\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5994 - accuracy: 0.3560\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5150 - accuracy: 0.4031\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5103 - accuracy: 0.3770\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.5074 - accuracy: 0.3822\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4712 - accuracy: 0.4084\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5202 - accuracy: 0.3665\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4554 - accuracy: 0.4031\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4525 - accuracy: 0.4555\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4744 - accuracy: 0.3822\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3466 - accuracy: 0.4712\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2779 - accuracy: 0.4764\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2495 - accuracy: 0.5026\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1706 - accuracy: 0.5340\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2362 - accuracy: 0.5497\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3165 - accuracy: 0.5131\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1786 - accuracy: 0.5340\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2516 - accuracy: 0.5131\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.4145 - accuracy: 0.4974\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1251 - accuracy: 0.5288\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0641 - accuracy: 0.5916\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.0609 - accuracy: 0.5707\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9841 - accuracy: 0.5864\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0141 - accuracy: 0.6073\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.9294 - accuracy: 0.6283\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8998 - accuracy: 0.6597\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0595 - accuracy: 0.5864\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9960 - accuracy: 0.6230\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0566 - accuracy: 0.6073\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9906 - accuracy: 0.6492\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8970 - accuracy: 0.6649\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.9332 - accuracy: 0.6649\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9406 - accuracy: 0.6492\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9105 - accuracy: 0.6963\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7159 - accuracy: 0.7382\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7297 - accuracy: 0.7382\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6977 - accuracy: 0.7539\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6121 - accuracy: 0.8010\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.6243 - accuracy: 0.7644\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7173 - accuracy: 0.7173\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6995 - accuracy: 0.7435\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8050 - accuracy: 0.7435\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5371 - accuracy: 0.8115\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4350 - accuracy: 0.8377\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4231 - accuracy: 0.8586\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4067 - accuracy: 0.8482\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4610 - accuracy: 0.8220\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.4576 - accuracy: 0.8272\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5438 - accuracy: 0.8325\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3641 - accuracy: 0.8534\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3999 - accuracy: 0.8377\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3751 - accuracy: 0.8639\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3016 - accuracy: 0.8953\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2884 - accuracy: 0.8901\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.2418 - accuracy: 0.9005\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2783 - accuracy: 0.9058\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2833 - accuracy: 0.8691\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2820 - accuracy: 0.8743\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2296 - accuracy: 0.9267\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2567 - accuracy: 0.9110\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3451 - accuracy: 0.9058\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2760 - accuracy: 0.8953\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.2840 - accuracy: 0.9162\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2163 - accuracy: 0.9267\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2126 - accuracy: 0.9372\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1801 - accuracy: 0.9267\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2329 - accuracy: 0.9005\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2783 - accuracy: 0.9110\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2118 - accuracy: 0.9215\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1681 - accuracy: 0.9476\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1608 - accuracy: 0.9581\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1477 - accuracy: 0.9529\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1088 - accuracy: 0.9529\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0955 - accuracy: 0.9791\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0695 - accuracy: 0.9738\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0831 - accuracy: 0.9686\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0787 - accuracy: 0.9738\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0719 - accuracy: 0.9843\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0737 - accuracy: 0.9895\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0612 - accuracy: 0.9843\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0703 - accuracy: 0.9843\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0722 - accuracy: 0.9738\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0609 - accuracy: 0.9895\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0626 - accuracy: 0.9895\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0530 - accuracy: 0.9895\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2898 - accuracy: 0.5455\n",
            "0.5454545617103577\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 146.2150 - accuracy: 0.1780\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 23.9656 - accuracy: 0.2408\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 4.2655 - accuracy: 0.2304\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 2.0234 - accuracy: 0.1728\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9409 - accuracy: 0.1675\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9460 - accuracy: 0.1466\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9460 - accuracy: 0.1518\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9460 - accuracy: 0.1518\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9458 - accuracy: 0.1518\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9456 - accuracy: 0.1518\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9457 - accuracy: 0.1571\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9460 - accuracy: 0.1466\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9458 - accuracy: 0.1518\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9457 - accuracy: 0.1571\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9456 - accuracy: 0.1518\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9458 - accuracy: 0.1466\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.9454 - accuracy: 0.1414\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 1.9461 - accuracy: 0.1518\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 1.9452 - accuracy: 0.1571\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9454 - accuracy: 0.1571\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9456 - accuracy: 0.1466\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9455 - accuracy: 0.1152\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9452 - accuracy: 0.1780\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9453 - accuracy: 0.1309\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9454 - accuracy: 0.1780\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9460 - accuracy: 0.1414\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9456 - accuracy: 0.1518\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9454 - accuracy: 0.1466\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9451 - accuracy: 0.1518\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9457 - accuracy: 0.1361\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9446 - accuracy: 0.1623\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9454 - accuracy: 0.1571\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9451 - accuracy: 0.1414\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9453 - accuracy: 0.1518\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9450 - accuracy: 0.1466\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9451 - accuracy: 0.1518\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9451 - accuracy: 0.1518\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9450 - accuracy: 0.1571\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9444 - accuracy: 0.1309\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9449 - accuracy: 0.1518\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9453 - accuracy: 0.1414\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9444 - accuracy: 0.1780\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9447 - accuracy: 0.1571\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9453 - accuracy: 0.1309\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9461 - accuracy: 0.1414\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9455 - accuracy: 0.1361\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9449 - accuracy: 0.1361\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9456 - accuracy: 0.1728\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9453 - accuracy: 0.1571\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9443 - accuracy: 0.1623\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9453 - accuracy: 0.1414\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9455 - accuracy: 0.1414\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9450 - accuracy: 0.1518\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9455 - accuracy: 0.1518\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9444 - accuracy: 0.1361\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9443 - accuracy: 0.1675\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9452 - accuracy: 0.1204\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9457 - accuracy: 0.1571\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9454 - accuracy: 0.1414\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9447 - accuracy: 0.1466\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9452 - accuracy: 0.1675\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9447 - accuracy: 0.1257\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9440 - accuracy: 0.1728\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9451 - accuracy: 0.1571\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9449 - accuracy: 0.1623\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9449 - accuracy: 0.1518\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9455 - accuracy: 0.1309\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9445 - accuracy: 0.1728\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9455 - accuracy: 0.1623\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9446 - accuracy: 0.1204\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9448 - accuracy: 0.1257\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9445 - accuracy: 0.1623\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9450 - accuracy: 0.1466\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9450 - accuracy: 0.1309\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9445 - accuracy: 0.1937\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9451 - accuracy: 0.1780\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9445 - accuracy: 0.1780\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9449 - accuracy: 0.1623\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9443 - accuracy: 0.1099\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9445 - accuracy: 0.1675\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9437 - accuracy: 0.1728\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9437 - accuracy: 0.1414\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9450 - accuracy: 0.1361\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9454 - accuracy: 0.1257\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9445 - accuracy: 0.1728\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9445 - accuracy: 0.1571\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9447 - accuracy: 0.1675\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9457 - accuracy: 0.1414\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9443 - accuracy: 0.1571\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9451 - accuracy: 0.1518\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9448 - accuracy: 0.1623\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9441 - accuracy: 0.1728\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9449 - accuracy: 0.1361\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9452 - accuracy: 0.1309\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9443 - accuracy: 0.1885\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9453 - accuracy: 0.1466\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9447 - accuracy: 0.1571\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9448 - accuracy: 0.1623\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9451 - accuracy: 0.1414\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9445 - accuracy: 0.1414\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9666 - accuracy: 0.0455\n",
            "0.04545454680919647\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 155.1680 - accuracy: 0.1354\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 27.4618 - accuracy: 0.1719\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 7.1157 - accuracy: 0.2552\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 3.2269 - accuracy: 0.2188\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 2.0542 - accuracy: 0.2031\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8922 - accuracy: 0.2031\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9031 - accuracy: 0.1927\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8868 - accuracy: 0.2292\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8304 - accuracy: 0.2292\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8308 - accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7962 - accuracy: 0.2760\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7610 - accuracy: 0.3073\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7407 - accuracy: 0.3177\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7081 - accuracy: 0.3281\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6412 - accuracy: 0.3438\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5865 - accuracy: 0.4062\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5742 - accuracy: 0.4167\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5177 - accuracy: 0.4219\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4713 - accuracy: 0.4115\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4873 - accuracy: 0.4010\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4147 - accuracy: 0.4323\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3739 - accuracy: 0.4844\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5578 - accuracy: 0.4115\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.5603 - accuracy: 0.3854\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3818 - accuracy: 0.4583\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2161 - accuracy: 0.5729\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2386 - accuracy: 0.5312\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2353 - accuracy: 0.5104\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1440 - accuracy: 0.5625\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1603 - accuracy: 0.5833\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0551 - accuracy: 0.5885\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0178 - accuracy: 0.5938\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0691 - accuracy: 0.5938\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8877 - accuracy: 0.6562\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.8989 - accuracy: 0.6250\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8486 - accuracy: 0.6927\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8151 - accuracy: 0.6927\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.9444 - accuracy: 0.6562\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7810 - accuracy: 0.7135\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8341 - accuracy: 0.7396\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7454 - accuracy: 0.7240\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7707 - accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8230 - accuracy: 0.7448\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6769 - accuracy: 0.7552\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7505 - accuracy: 0.7500\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7060 - accuracy: 0.7292\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.6919 - accuracy: 0.7500\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5453 - accuracy: 0.8073\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5752 - accuracy: 0.7552\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.5521 - accuracy: 0.7969\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4523 - accuracy: 0.8333\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3648 - accuracy: 0.8698\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4243 - accuracy: 0.8594\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3377 - accuracy: 0.9010\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2982 - accuracy: 0.8802\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3937 - accuracy: 0.8438\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3954 - accuracy: 0.8906\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3120 - accuracy: 0.8854\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2504 - accuracy: 0.9010\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2414 - accuracy: 0.9167\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3047 - accuracy: 0.8958\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2985 - accuracy: 0.8750\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1975 - accuracy: 0.9479\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1908 - accuracy: 0.9427\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1839 - accuracy: 0.9375\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1833 - accuracy: 0.9531\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2143 - accuracy: 0.9271\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1724 - accuracy: 0.9375\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1136 - accuracy: 0.9688\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0963 - accuracy: 0.9531\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1316 - accuracy: 0.9531\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1168 - accuracy: 0.9635\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1034 - accuracy: 0.9583\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1203 - accuracy: 0.9635\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0857 - accuracy: 0.9635\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0793 - accuracy: 0.9740\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0811 - accuracy: 0.9688\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0795 - accuracy: 0.9740\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1018 - accuracy: 0.9583\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0698 - accuracy: 0.9740\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0863 - accuracy: 0.9635\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0487 - accuracy: 0.9792\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0395 - accuracy: 0.9896\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0513 - accuracy: 0.9792\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0433 - accuracy: 0.9896\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0445 - accuracy: 0.9792\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0222 - accuracy: 0.9948\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0372 - accuracy: 0.9896\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0190 - accuracy: 0.9948\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0421 - accuracy: 0.9792\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0374 - accuracy: 0.9896\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0282 - accuracy: 0.9948\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0211 - accuracy: 0.9948\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0149 - accuracy: 0.9948\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0128 - accuracy: 0.9948\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0082 - accuracy: 0.9948\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7558 - accuracy: 0.7143\n",
            "0.7142857313156128\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 190.6311 - accuracy: 0.1458\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 21.6651 - accuracy: 0.2031\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 5.0907 - accuracy: 0.2031\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 2.0092 - accuracy: 0.1667\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9315 - accuracy: 0.1406\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9467 - accuracy: 0.1615\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9235 - accuracy: 0.1771\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9036 - accuracy: 0.1927\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8997 - accuracy: 0.2188\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8871 - accuracy: 0.1823\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8300 - accuracy: 0.1979\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7967 - accuracy: 0.2708\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8068 - accuracy: 0.2500\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7518 - accuracy: 0.2969\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7125 - accuracy: 0.3073\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7029 - accuracy: 0.2708\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6919 - accuracy: 0.3073\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6384 - accuracy: 0.3490\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.6225 - accuracy: 0.3490\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5891 - accuracy: 0.3125\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.5759 - accuracy: 0.3281\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5135 - accuracy: 0.4167\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5442 - accuracy: 0.3438\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5387 - accuracy: 0.3542\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.4102 - accuracy: 0.4010\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3531 - accuracy: 0.4531\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3636 - accuracy: 0.4531\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3264 - accuracy: 0.4792\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3470 - accuracy: 0.4844\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3243 - accuracy: 0.4479\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2743 - accuracy: 0.4792\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1853 - accuracy: 0.5208\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.1354 - accuracy: 0.5417\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.0581 - accuracy: 0.5990\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1932 - accuracy: 0.5469\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1322 - accuracy: 0.5677\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1782 - accuracy: 0.5781\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.1209 - accuracy: 0.6094\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0190 - accuracy: 0.6042\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.9573 - accuracy: 0.6510\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0864 - accuracy: 0.5469\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3219 - accuracy: 0.4948\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2514 - accuracy: 0.5417\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2276 - accuracy: 0.5573\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2176 - accuracy: 0.5469\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2510 - accuracy: 0.5365\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1295 - accuracy: 0.5729\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9398 - accuracy: 0.6562\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0044 - accuracy: 0.6250\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0205 - accuracy: 0.6302\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9778 - accuracy: 0.6354\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0409 - accuracy: 0.6302\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9095 - accuracy: 0.6719\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8760 - accuracy: 0.6615\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.8050 - accuracy: 0.6875\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7711 - accuracy: 0.7031\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.7120 - accuracy: 0.7500\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7041 - accuracy: 0.7448\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6898 - accuracy: 0.7292\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6360 - accuracy: 0.7448\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6228 - accuracy: 0.7552\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6160 - accuracy: 0.7552\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.6648 - accuracy: 0.7396\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6840 - accuracy: 0.7344\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7164 - accuracy: 0.7396\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.6423 - accuracy: 0.7292\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6204 - accuracy: 0.7240\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5607 - accuracy: 0.7969\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5412 - accuracy: 0.7812\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5468 - accuracy: 0.8021\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5136 - accuracy: 0.7865\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5141 - accuracy: 0.7865\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4745 - accuracy: 0.8229\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4916 - accuracy: 0.8021\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4980 - accuracy: 0.7917\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4710 - accuracy: 0.8229\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4758 - accuracy: 0.8125\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4570 - accuracy: 0.8177\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4556 - accuracy: 0.8177\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4490 - accuracy: 0.8073\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4210 - accuracy: 0.8333\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4300 - accuracy: 0.8177\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4135 - accuracy: 0.8438\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4164 - accuracy: 0.8281\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3943 - accuracy: 0.8438\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3936 - accuracy: 0.8385\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4040 - accuracy: 0.8333\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4113 - accuracy: 0.8333\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4009 - accuracy: 0.8438\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4172 - accuracy: 0.8229\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4036 - accuracy: 0.8281\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3959 - accuracy: 0.8490\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3750 - accuracy: 0.8438\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3902 - accuracy: 0.8438\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3799 - accuracy: 0.8385\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3878 - accuracy: 0.8229\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3908 - accuracy: 0.8385\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4798 - accuracy: 0.8177\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4533 - accuracy: 0.8177\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3838 - accuracy: 0.8385\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7358 - accuracy: 0.5238\n",
            "0.523809552192688\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 209.2691 - accuracy: 0.1979\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 10.7664 - accuracy: 0.2031\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 2.1371 - accuracy: 0.1406\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9417 - accuracy: 0.1458\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9425 - accuracy: 0.1667\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.9419 - accuracy: 0.1458\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9427 - accuracy: 0.1198\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9447 - accuracy: 0.1562\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9415 - accuracy: 0.1927\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9388 - accuracy: 0.1302\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9404 - accuracy: 0.1354\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.9342 - accuracy: 0.1667\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9213 - accuracy: 0.1562\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9325 - accuracy: 0.1771\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9009 - accuracy: 0.1927\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8903 - accuracy: 0.2031\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8644 - accuracy: 0.2031\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8776 - accuracy: 0.1875\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8596 - accuracy: 0.2240\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8681 - accuracy: 0.2031\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8889 - accuracy: 0.1823\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8707 - accuracy: 0.2240\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8577 - accuracy: 0.2135\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8916 - accuracy: 0.1979\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8280 - accuracy: 0.2083\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8249 - accuracy: 0.2083\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8359 - accuracy: 0.2240\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8105 - accuracy: 0.2083\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8521 - accuracy: 0.2292\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8312 - accuracy: 0.2344\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7919 - accuracy: 0.2500\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.7701 - accuracy: 0.2604\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7413 - accuracy: 0.2656\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7379 - accuracy: 0.2812\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6544 - accuracy: 0.2708\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6708 - accuracy: 0.3073\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.5714 - accuracy: 0.3542\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5713 - accuracy: 0.3229\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6463 - accuracy: 0.3021\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.6897 - accuracy: 0.2969\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6131 - accuracy: 0.2812\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6465 - accuracy: 0.3021\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5493 - accuracy: 0.3021\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.5404 - accuracy: 0.3542\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4973 - accuracy: 0.3906\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.4710 - accuracy: 0.4323\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4860 - accuracy: 0.4531\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3613 - accuracy: 0.4688\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3809 - accuracy: 0.4583\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.4291 - accuracy: 0.4688\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4021 - accuracy: 0.4583\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5010 - accuracy: 0.4323\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3820 - accuracy: 0.4740\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2903 - accuracy: 0.5573\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3559 - accuracy: 0.4948\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3314 - accuracy: 0.5208\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3208 - accuracy: 0.5260\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2381 - accuracy: 0.5885\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2292 - accuracy: 0.5417\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.1182 - accuracy: 0.6042\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0544 - accuracy: 0.6458\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0453 - accuracy: 0.6354\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0235 - accuracy: 0.6719\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0416 - accuracy: 0.6615\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9989 - accuracy: 0.6510\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0063 - accuracy: 0.6927\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9950 - accuracy: 0.6510\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9745 - accuracy: 0.6510\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9310 - accuracy: 0.7135\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.8977 - accuracy: 0.6823\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.8936 - accuracy: 0.7135\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.8906 - accuracy: 0.7083\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8339 - accuracy: 0.7240\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.8219 - accuracy: 0.7292\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7876 - accuracy: 0.7500\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7428 - accuracy: 0.7552\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7867 - accuracy: 0.7344\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7961 - accuracy: 0.7135\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0725 - accuracy: 0.6406\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9799 - accuracy: 0.6510\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.7775 - accuracy: 0.7344\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7253 - accuracy: 0.7604\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7348 - accuracy: 0.7656\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7108 - accuracy: 0.7500\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6762 - accuracy: 0.7865\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6220 - accuracy: 0.7917\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6144 - accuracy: 0.7917\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6140 - accuracy: 0.7917\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.6493 - accuracy: 0.7656\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6133 - accuracy: 0.8229\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6036 - accuracy: 0.8281\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6059 - accuracy: 0.8177\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5483 - accuracy: 0.8229\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5211 - accuracy: 0.8490\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4964 - accuracy: 0.8490\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4903 - accuracy: 0.8438\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5242 - accuracy: 0.8385\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5062 - accuracy: 0.8281\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5277 - accuracy: 0.8333\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4859 - accuracy: 0.8385\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9861 - accuracy: 0.3810\n",
            "0.380952388048172\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 155.0467 - accuracy: 0.1146\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 26.1874 - accuracy: 0.1771\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 5.2349 - accuracy: 0.1927\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 2.1420 - accuracy: 0.1719\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9660 - accuracy: 0.1510\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9307 - accuracy: 0.1562\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9236 - accuracy: 0.1823\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9137 - accuracy: 0.1719\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8902 - accuracy: 0.1667\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8699 - accuracy: 0.2344\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.8568 - accuracy: 0.2188\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8626 - accuracy: 0.2188\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7939 - accuracy: 0.2969\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7974 - accuracy: 0.2604\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7510 - accuracy: 0.2969\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7232 - accuracy: 0.2812\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6907 - accuracy: 0.3021\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.6805 - accuracy: 0.3125\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6273 - accuracy: 0.3281\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.6221 - accuracy: 0.2969\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.6562 - accuracy: 0.3542\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5836 - accuracy: 0.3802\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5704 - accuracy: 0.3490\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5480 - accuracy: 0.3958\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4630 - accuracy: 0.4271\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4049 - accuracy: 0.4792\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4809 - accuracy: 0.4688\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.4881 - accuracy: 0.4115\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.4615 - accuracy: 0.4427\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4182 - accuracy: 0.4635\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4049 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4233 - accuracy: 0.4635\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3028 - accuracy: 0.4688\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3098 - accuracy: 0.5156\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2702 - accuracy: 0.5365\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.3043 - accuracy: 0.5469\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1088 - accuracy: 0.6146\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.1395 - accuracy: 0.5990\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.1194 - accuracy: 0.5521\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1703 - accuracy: 0.5885\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1030 - accuracy: 0.5625\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1565 - accuracy: 0.5625\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.0156 - accuracy: 0.6094\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9316 - accuracy: 0.6406\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8459 - accuracy: 0.6719\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8375 - accuracy: 0.6979\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7943 - accuracy: 0.6771\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7478 - accuracy: 0.7344\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8078 - accuracy: 0.6979\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.7335 - accuracy: 0.7240\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6422 - accuracy: 0.7656\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.7084 - accuracy: 0.7396\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8164 - accuracy: 0.7396\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6821 - accuracy: 0.7135\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6723 - accuracy: 0.7656\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.7664 - accuracy: 0.7552\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.7951 - accuracy: 0.7292\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5519 - accuracy: 0.8021\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5210 - accuracy: 0.8177\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5611 - accuracy: 0.8177\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4251 - accuracy: 0.8646\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5240 - accuracy: 0.8333\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5968 - accuracy: 0.8021\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.6383 - accuracy: 0.7552\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5414 - accuracy: 0.8021\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4276 - accuracy: 0.8125\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5514 - accuracy: 0.7969\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4640 - accuracy: 0.8073\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3579 - accuracy: 0.8750\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.5584 - accuracy: 0.8125\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4646 - accuracy: 0.8281\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4771 - accuracy: 0.8281\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5608 - accuracy: 0.7969\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5016 - accuracy: 0.8438\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4272 - accuracy: 0.8646\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3368 - accuracy: 0.8698\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3563 - accuracy: 0.8802\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4034 - accuracy: 0.8385\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5440 - accuracy: 0.8073\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4664 - accuracy: 0.7969\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3560 - accuracy: 0.8698\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3380 - accuracy: 0.8594\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3214 - accuracy: 0.8802\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3174 - accuracy: 0.8594\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2582 - accuracy: 0.9010\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2234 - accuracy: 0.9115\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.2524 - accuracy: 0.9062\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.2500 - accuracy: 0.8906\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1855 - accuracy: 0.9323\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2272 - accuracy: 0.9115\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3374 - accuracy: 0.8542\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2960 - accuracy: 0.8906\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3268 - accuracy: 0.8646\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2157 - accuracy: 0.9271\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3046 - accuracy: 0.8854\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2835 - accuracy: 0.8906\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3551 - accuracy: 0.8750\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3746 - accuracy: 0.8490\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2126 - accuracy: 0.9062\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2045 - accuracy: 0.9167\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7316 - accuracy: 0.6190\n",
            "0.6190476417541504\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 164.6204 - accuracy: 0.1510\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 17.1847 - accuracy: 0.2448\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 2.7439 - accuracy: 0.2031\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9566 - accuracy: 0.2135\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9427 - accuracy: 0.1823\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8989 - accuracy: 0.1823\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8750 - accuracy: 0.2292\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8315 - accuracy: 0.2240\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7414 - accuracy: 0.2812\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7308 - accuracy: 0.3073\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.6667 - accuracy: 0.3438\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.6222 - accuracy: 0.3438\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.5844 - accuracy: 0.3854\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5641 - accuracy: 0.4010\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.5315 - accuracy: 0.3802\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4187 - accuracy: 0.3958\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5200 - accuracy: 0.3646\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4719 - accuracy: 0.4271\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4131 - accuracy: 0.4115\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3822 - accuracy: 0.4688\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3856 - accuracy: 0.4375\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4005 - accuracy: 0.3958\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3869 - accuracy: 0.4635\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3115 - accuracy: 0.4948\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2571 - accuracy: 0.4844\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2277 - accuracy: 0.4948\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2080 - accuracy: 0.4688\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1780 - accuracy: 0.5365\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1912 - accuracy: 0.4740\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1918 - accuracy: 0.5312\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1544 - accuracy: 0.5417\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2503 - accuracy: 0.4896\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1357 - accuracy: 0.5365\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2795 - accuracy: 0.5156\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1630 - accuracy: 0.5365\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1951 - accuracy: 0.5052\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0984 - accuracy: 0.5312\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2147 - accuracy: 0.5312\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.1817 - accuracy: 0.5729\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2302 - accuracy: 0.5052\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1623 - accuracy: 0.5312\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.2199 - accuracy: 0.5469\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1452 - accuracy: 0.5625\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1135 - accuracy: 0.5781\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0275 - accuracy: 0.6042\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9452 - accuracy: 0.6302\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9284 - accuracy: 0.6198\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0355 - accuracy: 0.5938\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1108 - accuracy: 0.5573\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.0093 - accuracy: 0.6146\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9244 - accuracy: 0.6198\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8064 - accuracy: 0.6615\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9435 - accuracy: 0.5938\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9031 - accuracy: 0.6510\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8193 - accuracy: 0.7083\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8624 - accuracy: 0.6979\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8701 - accuracy: 0.6875\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7897 - accuracy: 0.6927\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7513 - accuracy: 0.7188\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.7016 - accuracy: 0.7240\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.8764 - accuracy: 0.6927\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.7166 - accuracy: 0.7344\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5558 - accuracy: 0.7760\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6181 - accuracy: 0.7760\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5913 - accuracy: 0.7917\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5407 - accuracy: 0.8177\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4798 - accuracy: 0.8125\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5442 - accuracy: 0.7917\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4374 - accuracy: 0.8125\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3963 - accuracy: 0.8385\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4523 - accuracy: 0.8281\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.4000 - accuracy: 0.8594\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3832 - accuracy: 0.8594\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.3436 - accuracy: 0.8333\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3441 - accuracy: 0.8542\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2935 - accuracy: 0.8906\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.2881 - accuracy: 0.9010\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2356 - accuracy: 0.9062\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2284 - accuracy: 0.9062\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2200 - accuracy: 0.9167\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1851 - accuracy: 0.9271\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.1972 - accuracy: 0.9167\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2741 - accuracy: 0.8906\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2691 - accuracy: 0.9219\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3584 - accuracy: 0.8854\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4106 - accuracy: 0.8594\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4047 - accuracy: 0.8438\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2924 - accuracy: 0.9010\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4092 - accuracy: 0.8542\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2958 - accuracy: 0.9062\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3220 - accuracy: 0.8906\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1861 - accuracy: 0.9427\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1392 - accuracy: 0.9479\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1341 - accuracy: 0.9531\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1138 - accuracy: 0.9792\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1196 - accuracy: 0.9531\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1288 - accuracy: 0.9427\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0833 - accuracy: 0.9792\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1033 - accuracy: 0.9688\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1135 - accuracy: 0.9688\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0842 - accuracy: 0.5238\n",
            "0.523809552192688\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 151.3316 - accuracy: 0.1250\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 20.7054 - accuracy: 0.2031\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 4.8583 - accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 2.1455 - accuracy: 0.2344\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.8854 - accuracy: 0.1771\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9013 - accuracy: 0.1771\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8795 - accuracy: 0.1562\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8285 - accuracy: 0.1927\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8626 - accuracy: 0.1875\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8047 - accuracy: 0.1927\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.7744 - accuracy: 0.2135\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7109 - accuracy: 0.2448\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6935 - accuracy: 0.2656\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.6789 - accuracy: 0.3125\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 1.7796 - accuracy: 0.2656\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 1.7470 - accuracy: 0.2604\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 1.6282 - accuracy: 0.3073\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 1.5554 - accuracy: 0.3438\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 1.5046 - accuracy: 0.3802\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 1.5849 - accuracy: 0.3594\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 1.4751 - accuracy: 0.3802\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 1.4176 - accuracy: 0.3958\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 1.3498 - accuracy: 0.4479\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 1.3033 - accuracy: 0.4323\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 1.2421 - accuracy: 0.5052\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 1s 92ms/step - loss: 1.1836 - accuracy: 0.5052\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 1.1807 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 1.1367 - accuracy: 0.5365\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 1s 90ms/step - loss: 1.1037 - accuracy: 0.5781\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 1s 84ms/step - loss: 1.1492 - accuracy: 0.5260\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 1s 88ms/step - loss: 1.0402 - accuracy: 0.5677\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 1.0738 - accuracy: 0.5521\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 1.0871 - accuracy: 0.5573\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9413 - accuracy: 0.6250\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0199 - accuracy: 0.5885\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9982 - accuracy: 0.6094\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9799 - accuracy: 0.5729\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8929 - accuracy: 0.6094\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9325 - accuracy: 0.6146\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9107 - accuracy: 0.6250\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.8173 - accuracy: 0.6510\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8600 - accuracy: 0.6458\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8285 - accuracy: 0.6667\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7577 - accuracy: 0.6719\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7711 - accuracy: 0.6771\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7528 - accuracy: 0.6771\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7239 - accuracy: 0.6927\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6945 - accuracy: 0.7031\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6924 - accuracy: 0.7240\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6116 - accuracy: 0.7500\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5851 - accuracy: 0.7812\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6179 - accuracy: 0.7292\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5827 - accuracy: 0.7917\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4817 - accuracy: 0.7917\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4947 - accuracy: 0.7917\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6024 - accuracy: 0.7812\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5896 - accuracy: 0.7552\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4462 - accuracy: 0.8073\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4505 - accuracy: 0.8177\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4116 - accuracy: 0.8229\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3807 - accuracy: 0.8698\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3269 - accuracy: 0.8906\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3552 - accuracy: 0.8646\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3560 - accuracy: 0.8802\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3402 - accuracy: 0.8854\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3130 - accuracy: 0.8802\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3280 - accuracy: 0.8958\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3985 - accuracy: 0.8385\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4768 - accuracy: 0.8073\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4096 - accuracy: 0.8906\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3639 - accuracy: 0.8750\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3453 - accuracy: 0.8750\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3271 - accuracy: 0.8802\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2907 - accuracy: 0.8958\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3374 - accuracy: 0.8646\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3899 - accuracy: 0.8646\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4795 - accuracy: 0.8646\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.3869 - accuracy: 0.8802\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.2878 - accuracy: 0.8750\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2456 - accuracy: 0.8802\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.2198 - accuracy: 0.9531\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1594 - accuracy: 0.9271\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1750 - accuracy: 0.9427\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1211 - accuracy: 0.9635\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1388 - accuracy: 0.9635\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1561 - accuracy: 0.9427\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2253 - accuracy: 0.9531\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1540 - accuracy: 0.9323\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1703 - accuracy: 0.9479\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1129 - accuracy: 0.9479\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0757 - accuracy: 0.9792\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1184 - accuracy: 0.9688\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0700 - accuracy: 0.9792\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1023 - accuracy: 0.9635\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1284 - accuracy: 0.9479\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0826 - accuracy: 0.9688\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0812 - accuracy: 0.9688\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0624 - accuracy: 0.9792\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0554 - accuracy: 0.9896\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0295 - accuracy: 0.9896\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9587 - accuracy: 0.5714\n",
            "0.5714285969734192\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 177.3516 - accuracy: 0.1406\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 22.6799 - accuracy: 0.1823\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 4.3012 - accuracy: 0.2135\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9613 - accuracy: 0.1562\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.9417 - accuracy: 0.1354\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9346 - accuracy: 0.1302\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9424 - accuracy: 0.1562\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.9356 - accuracy: 0.1458\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.9384 - accuracy: 0.1510\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9228 - accuracy: 0.1667\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.9021 - accuracy: 0.1615\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8861 - accuracy: 0.1458\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8908 - accuracy: 0.1719\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.8591 - accuracy: 0.1823\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 1.8409 - accuracy: 0.2031\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.8487 - accuracy: 0.2083\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.8216 - accuracy: 0.2656\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.7902 - accuracy: 0.2031\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.8007 - accuracy: 0.2708\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7718 - accuracy: 0.2708\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.7925 - accuracy: 0.2500\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6635 - accuracy: 0.2812\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.6862 - accuracy: 0.2865\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6507 - accuracy: 0.3229\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6266 - accuracy: 0.3438\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.5647 - accuracy: 0.4010\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.5814 - accuracy: 0.3385\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.6216 - accuracy: 0.3854\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4982 - accuracy: 0.4010\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.5102 - accuracy: 0.4271\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.4713 - accuracy: 0.4219\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4217 - accuracy: 0.4375\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3884 - accuracy: 0.4427\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3651 - accuracy: 0.4427\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3257 - accuracy: 0.4479\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.4285 - accuracy: 0.4167\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.4390 - accuracy: 0.4688\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.3366 - accuracy: 0.4635\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3240 - accuracy: 0.4479\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.3719 - accuracy: 0.4740\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2822 - accuracy: 0.4688\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.3680 - accuracy: 0.4479\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2557 - accuracy: 0.5104\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1.2694 - accuracy: 0.4688\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2085 - accuracy: 0.4844\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1903 - accuracy: 0.5156\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2066 - accuracy: 0.5260\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1786 - accuracy: 0.5208\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.2843 - accuracy: 0.4479\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.2841 - accuracy: 0.5156\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.1474 - accuracy: 0.5625\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1701 - accuracy: 0.5312\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1654 - accuracy: 0.5260\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.1474 - accuracy: 0.5260\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.0484 - accuracy: 0.5469\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 1.1249 - accuracy: 0.5312\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1188 - accuracy: 0.5260\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.9796 - accuracy: 0.5469\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9861 - accuracy: 0.6250\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.1151 - accuracy: 0.5938\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 1.0690 - accuracy: 0.5573\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9645 - accuracy: 0.6250\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 1.0544 - accuracy: 0.5677\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9227 - accuracy: 0.6406\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.8398 - accuracy: 0.6250\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8443 - accuracy: 0.6979\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9195 - accuracy: 0.6458\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.7971 - accuracy: 0.6771\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7320 - accuracy: 0.7135\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.8198 - accuracy: 0.6562\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.6812 - accuracy: 0.7448\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7583 - accuracy: 0.6875\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9432 - accuracy: 0.6250\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.9115 - accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.8456 - accuracy: 0.7031\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.9428 - accuracy: 0.6510\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7608 - accuracy: 0.7188\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.7081 - accuracy: 0.7188\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.7092 - accuracy: 0.7448\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.6443 - accuracy: 0.7500\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5836 - accuracy: 0.7760\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.6477 - accuracy: 0.7292\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5501 - accuracy: 0.7917\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5264 - accuracy: 0.8177\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5033 - accuracy: 0.8177\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5278 - accuracy: 0.7708\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.5511 - accuracy: 0.7865\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5614 - accuracy: 0.7448\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.5474 - accuracy: 0.7760\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4573 - accuracy: 0.8229\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4502 - accuracy: 0.7812\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.4566 - accuracy: 0.8073\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.3919 - accuracy: 0.8438\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3923 - accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.3624 - accuracy: 0.8542\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3787 - accuracy: 0.8542\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3981 - accuracy: 0.8073\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3509 - accuracy: 0.8490\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3593 - accuracy: 0.8490\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.3765 - accuracy: 0.8333\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0530 - accuracy: 0.5238\n",
            "0.523809552192688\n",
            "0.5038961187005043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCkxD4Def-p4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ten fold cross validation on the whole dataset \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "acc = 0\n",
        "\n",
        "kf = KFold(n_splits = 10, random_state = 10, shuffle = True)\n",
        "\n",
        "kf.get_n_splits(image_data)\n",
        "historys_val = []\n",
        "\n",
        "for train_index,test_index in kf.split(image_data):\n",
        "\n",
        "  #print(train_index,test_index)\n",
        "  X_train,X_test = image_data[train_index],image_data[test_index]\n",
        "  y_train,y_test = Y[train_index], Y[test_index]\n",
        "  #print( y_val_train,y_val_test)\n",
        "\n",
        "\n",
        "  \n",
        "  model = CNN_model_with_0_neurons(num_of_classes)\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "  \n",
        "  mycallback = myCallback()\n",
        "  train_datagen = image.ImageDataGenerator(\n",
        "      rescale= 1./255,\n",
        "      rotation_range = 2 ,\n",
        "      horizontal_flip =True,\n",
        "  )\n",
        "  train_datagen.fit(X_train)\n",
        "\n",
        "  validation_datagen = image.ImageDataGenerator(rescale = 1./255,\n",
        "                                                rotation_range=2,\n",
        "                                                horizontal_flip = True)\n",
        "  validation_datagen.fit(X_test)\n",
        "  print(len(X_train))\n",
        "\n",
        "  # fits the model on batches with real-time data augmentation:\n",
        "  history = model.fit(train_datagen.flow(X_train, y_train, batch_size=16), \n",
        "                              epochs = 100,\n",
        "                              validation_data=validation_datagen.flow(X_test, y_test, batch_size = 16), \n",
        "                              callbacks = [mycallback] )\n",
        "  historys_val.append(history)\n",
        "  #print(test_loss,test_acc )\n",
        "  #model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  #optimizer='adam',\n",
        "                  #metrics=['accuracy'])\n",
        "  #model.fit(x_val_train,y_val_train,epochs=80)\n",
        "  #test_loss,test_acc=model.evaluate(x_val_test,y_val_test)\n",
        "#cross_val_score(model,x_val_test,y_val_tes,cv=10)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r_nkLlyvCTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from operator import add \n",
        "\n",
        "avg_loss = [0.0]*100\n",
        "avg_acc = [0.0]*100\n",
        "avg_val_acc = [0.0]*100\n",
        "avg_val_loss = [0.0]*100\n",
        "for i , history in enumerate(historys_val):\n",
        "  avg_loss = list(map ( add, history.history['loss'], avg_loss))\n",
        "  avg_acc = list(map(add,history.history['accuracy'], avg_acc))\n",
        "  avg_val_loss = list(map(add,history.history['val_loss'],avg_val_loss))\n",
        "  avg_val_acc = list(map(add,history.history['val_accuracy'], avg_val_acc))\n",
        "\n",
        "fig = plt.figure(figsize= (12,8))\n",
        "epochs = range(100)\n",
        "i = 1\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, avg_acc, 'r',label =  \"Training Accuracy\")\n",
        "plt.plot(epochs, avg_val_acc, 'b',label = \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy({} neurons)'.format(i *256))\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, avg_loss, 'r',label = \"Training Loss\")\n",
        "plt.plot(epochs, avg_val_loss, 'b', label = \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.title('Training and validation loss({} neurons)'.format(i*256))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}